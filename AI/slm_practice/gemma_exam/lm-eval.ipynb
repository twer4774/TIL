{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harness 평가방법\n",
    "- LM-Evaluation-Harness v0.4.0\n",
    "- 라이브러리를 그대로 사용하게되면, 버전차이로 소스를 수정해야할 가능성이 높음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LM-Eval\n",
    "!pip install git+https://github.com/EleutherAI/lm-evalutation-harness.git@big-refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_eval import api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정 기반의 새로운 Evaluation task 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_boolq_string = '''\n",
    "task: demo_boolq\n",
    "dataset_path: super_glue\n",
    "dataset_name: boolq\n",
    "output_type: multiple_choice\n",
    "training_split: train\n",
    "validation_split: validation\n",
    "doc_to_text: \"{{passage}}\\nQuestion: {{question}}?\\nAnswer:\"\n",
    "doc_to_target: label\n",
    "doc_to_choice: [\"no\", \"yes\"]\n",
    "should_decontaminate: true\n",
    "doc_to_decontamination_query: passage\n",
    "metric_list:\n",
    "  - metric: acc\n",
    "'''\n",
    "with open('boolq.yaml', 'w') as f:\n",
    "    f.write(YAML_boolq_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=wonik-hi/phi3_fine_tuning \\\n",
    "    --include_path ./ \\\n",
    "    --tasks demo_boolq \\\n",
    "    --limit 10\n",
    "\n",
    "\"\"\"\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-2.8b \\\n",
    "    --include_path ./ \\\n",
    "    --tasks demo_boolq \\\n",
    "    --limit 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_cola_string = '''\n",
    "tag: yes_or_no_tasks\n",
    "task: demo_cola\n",
    "dataset_path: glue\n",
    "dataset_name: cola\n",
    "output_type: multiple_choice\n",
    "training_split: train\n",
    "validation_split: validation\n",
    "doc_to_text: \"{{sentence}}\\nQuestion: Does this sentence make sense?\\nAnswer:\"\n",
    "doc_to_target: label\n",
    "doc_to_choice: [\"no\", \"yes\"]\n",
    "should_decontaminate: true\n",
    "doc_to_decontamination_query: sentence\n",
    "metric_list:\n",
    "  - metric: acc\n",
    "'''\n",
    "with open('cola.yaml', 'w') as f:\n",
    "    f.write(YAML_cola_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !accelerate launch --no_python\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-2.8b \\\n",
    "    --include_path ./ \\\n",
    "    --tasks yes_or_no_tasks \\\n",
    "    --limit 10 \\\n",
    "    --output output/yes_or_no_tasks/ \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_mmlu_geo_string = '''\n",
    "task: demo_mmlu_high_school_geography\n",
    "dataset_path: cais/mmlu\n",
    "dataset_name: high_school_geography\n",
    "description: \"The following are multiple choice questions (with answers) about high school geography.\\n\\n\"\n",
    "test_split: test\n",
    "fewshot_split: dev\n",
    "fewshot_config:\n",
    "  sampler: first_n\n",
    "output_type: multiple_choice\n",
    "doc_to_text: \"{{question.strip()}}\\nA. {{choices[0]}}\\nB. {{choices[1]}}\\nC. {{choices[2]}}\\nD. {{choices[3]}}\\nAnswer:\"\n",
    "doc_to_choice: [\"A\", \"B\", \"C\", \"D\"]\n",
    "doc_to_target: answer\n",
    "metric_list:\n",
    "  - metric: acc\n",
    "    aggregation: mean\n",
    "    higher_is_better: true\n",
    "  - metric: acc_norm\n",
    "    aggregation: mean\n",
    "    higher_is_better: true\n",
    "'''\n",
    "with open('mmlu_high_school_geography.yaml', 'w') as f:\n",
    "    f.write(YAML_mmlu_geo_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !accelerate launch --no_python\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-2.8b \\\n",
    "    --include_path ./ \\\n",
    "    --tasks demo_mmlu_high_school_geography \\\n",
    "    --limit 10 \\\n",
    "    --output output/mmlu_high_school_geography/ \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.view(\"output/mmlu_high_school_geography_continuation/pretrained__EleutherAI__pythia-2.8b_demo_mmlu_high_school_geography_continuation.jsonl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAML Fields 유형 설정\n",
    "- output_type\n",
    "    - loglikehood\n",
    "    - loglikehood_rolling\n",
    "    - multiple_choice\n",
    "    - greedy_until\n",
    "\n",
    "- core prompt\n",
    "    - doc_to_text : 모델에 대한 입력으로 사용될 프롬프트 템플릿\n",
    "    - doc_to_choice : 모델의 연속으로 사용될 사용 가능한 선택 사항. output_type이 multiple_choice일때 사용\n",
    "    - doc_to_target : output_type이 multiple_choice인 경우 정답에 해당하는 인덱스일 수 도 있고, 답변 문자열 자체일 수도 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_mmlu_geo_string = '''\n",
    "include: mmlu_high_school_geography.yaml\n",
    "task: demo_mmlu_high_school_geography_function_prompt\n",
    "doc_to_text: !function utils.doc_to_text\n",
    "doc_to_choice: \"{{choices}}\"\n",
    "'''\n",
    "with open('demo_mmlu_high_school_geography_function_prompt.yaml', 'w') as f:\n",
    "    f.write(YAML_mmlu_geo_string)\n",
    "\n",
    "DOC_TO_TEXT = '''\n",
    "def doc_to_text(x):\n",
    "    question = x[\"question\"].strip()\n",
    "    choices = x[\"choices\"]\n",
    "    option_a = choices[0]\n",
    "    option_b = choices[1]\n",
    "    option_c = choices[2]\n",
    "    option_d = choices[3]\n",
    "    return f\"{question}\\\\nA. {option_a}\\\\nB. {option_b}\\\\nC. {option_c}\\\\nD. {option_d}\\\\nAnswer:\"\n",
    "'''\n",
    "with open('utils.py', 'w') as f:\n",
    "    f.write(DOC_TO_TEXT)\n",
    "\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-2.8b \\\n",
    "    --include_path ./ \\\n",
    "    --tasks demo_mmlu_high_school_geography_function_prompt \\\n",
    "    --limit 10 \\\n",
    "    --output output/demo_mmlu_high_school_geography_function_prompt/ \\\n",
    "    --log_samples\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
