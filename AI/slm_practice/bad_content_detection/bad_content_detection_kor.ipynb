{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어 비속어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hate_dataset = load_dataset(\"SJ-Donald/kor-hate-sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_train = hate_dataset['train']\n",
    "hate_eval = hate_dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hate_train = pd.DataFrame(hate_train)\n",
    "hate_eval = pd.DataFrame(hate_eval)\n",
    "\n",
    "hate_train = hate_train[['문장', 'hate']]\n",
    "hate_eval = hate_eval[['문장', 'hate']]\n",
    "\n",
    "hate_train.columns=['text', 'label']\n",
    "hate_eval.columns=['text', 'label']\n",
    "\n",
    "hate_train['label_text'] = 0\n",
    "for i in range(len(hate_train)):\n",
    "  if hate_train['label'].iloc[i] == 1:\n",
    "    hate_train['label_text'].iloc[i] = 'toxic'\n",
    "  else:\n",
    "    hate_train['label_text'].iloc[i] = 'not toxic'\n",
    "\n",
    "hate_eval['label_text'] = 0\n",
    "for i in range(len(hate_eval)):\n",
    "  if hate_eval['label'].iloc[i] == 1:\n",
    "    hate_eval['label_text'].iloc[i] = 'toxic'\n",
    "  else:\n",
    "    hate_eval['label_text'].iloc[i] = 'not toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "hate_train = Dataset.from_pandas(hate_train)\n",
    "hate_eval = Dataset.from_pandas(hate_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "  return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "hate_train = hate_train.map(preprocess_function, batched=True)\n",
    "hate_eval = hate_eval.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 비속어\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"beomi/KcELECTRA-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  load_accuracy = load(\"accuracy\")\n",
    "  logits, labels = eval_pred\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  accuracy = load_accuracy.compute(\n",
    "    predictions=predictions, references=labels)[\"accuracy\"]\n",
    "  return {\"accuracy\": accuracy}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"hate\",\n",
    "  evaluation_strategy = \"epoch\",\n",
    "  save_strategy = \"epoch\",\n",
    "  learning_rate=2e-5,\n",
    "  per_device_train_batch_size=8,\n",
    "  per_device_eval_batch_size=8,\n",
    "  #num_train_epochs=2,\n",
    "  num_train_epochs=0.2,\n",
    "  weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset=hate_train,\n",
    "  eval_dataset=hate_eval,\n",
    "  tokenizer=tokenizer,\n",
    "  data_collator=data_collator,\n",
    "  compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from google.colab import userdata\n",
    "\n",
    "# OpenAIKey = userdata.get(\"OPENAI_KEY\") # OPENAI KEY\n",
    "client = OpenAI(api_key=\"sk-proj-\")\n",
    "\n",
    "def detect_hate(input_text):\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    messages = [\n",
    "          {\"role\": \"system\",\n",
    "           \"content\" :\n",
    "           \"\"\"너는 콘텐츠 운영 전문이가이다.\"\"\"},\n",
    "          {\"role\": \"user\",\n",
    "           \"content\" : \"이게 혐오표현인가요?  ```%s```\" %(input_text)}])\n",
    "  res = response.choices[0].message.content\n",
    "  return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_hate(\"그렇게 게임하면 어떡하냐 방송 접어라 허접아\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"wonik-hi/ko_bad_content_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_train.push_to_hub(\"wonik-hi/ko_bad_content_train\")\n",
    "hate_eval.push_to_hub(\"wonik-hi/ko_bad_content_eval\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
