{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime kor\n",
    "- 한국어 비속어 분포도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "hate_dataset = load_dataset(\"SJ-Donald/kor-hate-sentence\")\n",
    "train2 = hate_dataset['train']\n",
    "train1 = hate_dataset['validation']\n",
    "\n",
    "train2 = pd.DataFrame(train2)\n",
    "train1 = pd.DataFrame(train1)\n",
    "\n",
    "train_all = pd.concat([train1, train2])\n",
    "train_all = train_all.reset_index()\n",
    "\n",
    "train_all = train_all[['문장', 'hate']]\n",
    "train_all.columns=['comment_text', 'toxic']\n",
    "\n",
    "# train2 = train2[['문장', 'hate']]\n",
    "# train2.columns=['comment_text', 'toxic']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text = train_all.comment_text\n",
    "y_train = train_all.toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_text.head(), y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(y_train, bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, sklearn.metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "x_train = vectorizer.fit_transform(x_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(x_train)\n",
    "\n",
    "print(\"정확도: \", sklearn.metrics.accuracy_score(y_train, pred))\n",
    "print(\"confusion matrix: \\n\", sklearn.metrics.confusion_matrix(y_train, pred, normalize='pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_by_y_pred(y, p):\n",
    "  return [i for i in range(x_train.shape[0]) if y_train[i]==y and pred[i]==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = get_text_by_y_pred(0,0)\n",
    "fn = get_text_by_y_pred(0,1)\n",
    "fp = get_text_by_y_pred(1,0)\n",
    "tn = get_text_by_y_pred(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "def predict_pipe(x):\n",
    "  x = vectorizer.transform(x)\n",
    "  x = clf.predict(x)\n",
    "  return x\n",
    "\n",
    "# i 번째 훈련 데이터를 Lime으로 분석해서 노트북에 표시\n",
    "def explain(i, text=None, cls=None):\n",
    "  if not text and not cls:\n",
    "    text, cls = x_train_text[i], y_train[i]\n",
    "  class_names=[\"Normal\", \"Toxic\"]\n",
    "\n",
    "  # Lime 분석\n",
    "  pipe = make_pipeline(vectorizer, clf)\n",
    "  explainer = LimeTextExplainer(class_names=class_names)\n",
    "  exp = explainer.explain_instance(text, pipe.predict_proba)\n",
    "\n",
    "  # 분류기로 예측한 결과 표시\n",
    "  pred = clf.predict(vectorizer.transform([text])[0])\n",
    "  pred = \"Toxic\" if(pred == 1) else \"Normal\"\n",
    "  cls = \"Toxic\" if(cls == 1) else \"Normal\"\n",
    "\n",
    "  print()\n",
    "  print(f\"#{i} Predict: {pred} Real: {cls}\")\n",
    "  \n",
    "  # 노트북에 표시\n",
    "  exp.show_in_notebook(text=text)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in np.random.choice(fn, 10):\n",
    "for i in [2312, 213, 123, 1424, 1234]:\n",
    "  explain(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"나는 너무 착하다.  mms://a352.l5671334351.c56713.n.lm.akamaistream.net/D/352/56713/v0001/reflector:34351\"\"\"\n",
    "#eval(text, 1)\n",
    "#explain(text, 1)\n",
    "explain(1, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positive 로 분류된 값들의 문자열 길이 분포\n",
    "fp_len = [min(len(x_train_text[i]), 500) for i in fp]\n",
    "plt.hist(fp_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shorts = [i for i in fp if len(x_train_text[i]) < 100]\n",
    "longs = [i for i in fp if len(x_train_text[i]) >= 100]\n",
    "\n",
    "shorts = np.random.choice(shorts, 5)\n",
    "longs = np.random.choice(longs, 5)\n",
    "\n",
    "print(shorts)\n",
    "for i in shorts:\n",
    "  explain(i)\n",
    "\n",
    "print(longs)\n",
    "for i in longs:\n",
    "  explain(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열에서 악성 단어를 찾아내서 *로 바꿉니다.\n",
    "def filter_toxic(text):\n",
    "  pipe = make_pipeline(vectorizer, clf)\n",
    "  pred = clf.predict(vectorizer.transform([text])[0])\n",
    "\n",
    "  explainer = LimeTextExplainer(class_names=[0, 1])\n",
    "  exp = explainer.explain_instance(text, pipe.predict_proba)\n",
    "\n",
    "  result = exp.as_list()\n",
    "  toxic_list = [x[0] for x in result if x[1] >= 0.1]\n",
    "\n",
    "  filtered = text\n",
    "  for toxic in toxic_list:\n",
    "    filtered = filtered.replace(toxic, \"*\" * len(toxic))\n",
    "\n",
    "  print(\"=====================\")\n",
    "  print(\"Original Text: \\n{}\\n\\nFiltered: \\n{}\".format(text, filtered))\n",
    "  print(\"=====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_toxic(\"나는 존나 바보입니다.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
