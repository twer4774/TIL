{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime\n",
    "- 비속어 검출, 분포도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(\"/content/drive/MyDrive/bad_content_dectection/train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text = train.comment_text\n",
    "y_train = train[train.columns[2:]].sum(axis=1).map(lambda x: (int)(min(x, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_text.head(), y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(y_train, bins=2)\n",
    "# 데이터 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "# 아래 TF-IDF를 적용하면 결과가 개선된다.\n",
    "# vectorizer = TfidfVectorizer(min_df=10, stop_words='english')\n",
    "x_train = vectorizer.fit_transform(x_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 학습모델\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 정확도 확인\n",
    "pred = clf.predict(x_train)\n",
    "\n",
    "print(\"정확도: \", sklearn.metrics.accuracy_score(y_train, pred))\n",
    "print(\"혼돈 매트릭스: \\n\", sklearn.metrics.confusion_matrix(y_train, pred, normalize='pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_by_y_pred(y, p):\n",
    "  return [i for i in range(x_train.shape[0]) if y_train[i] == y and pred[i] == p]\n",
    "\n",
    "# 혼돈 매트릭스에 각 원소에 해당하는 훈련값들의 인덱스를 가져옵니다.\n",
    "tp = get_text_by_y_pred(0, 0)\n",
    "fn = get_text_by_y_pred(0, 1)\n",
    "fp = get_text_by_y_pred(1, 0)\n",
    "tn = get_text_by_y_pred(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "def predict_pipe(x):\n",
    "  x = vectorizer.transform(x)\n",
    "  x = clf.predict(x)\n",
    "  return x\n",
    "\n",
    "# i 번째 훈련 데이터를 Lime으로 분석해서 노트북에 표시합니다.\n",
    "def explain(i, text=None, cls=None):\n",
    "  if not text and not cls:\n",
    "    text, cls = x_train_text[i], y_train[i]\n",
    "\n",
    "  class_names=[\"Normal\", \"Toxic\"]\n",
    "\n",
    "  # Lime 분석\n",
    "  pipe = make_pipeline(vectorizer, clf)\n",
    "  explainer = LimeTextExplainer(class_names=class_names)\n",
    "  exp = explainer.explain_instance(text, pipe.predict_proba)\n",
    "\n",
    "  # 분류기로 예측한 결과 표시\n",
    "  pred = clf.predict(vectorizer.transform([text])[0])\n",
    "  pred = \"Toxic\" if(pred == 1) else \"Normal\"\n",
    "  cls = \"Toxic\" if(cls == 1) else \"Normal\"\n",
    "\n",
    "  print()\n",
    "  print(f\"#{i} Predict: {pred} Real: {cls}\")\n",
    "\n",
    "  # 노트북에 표시\n",
    "  exp.show_in_notebook(text=text)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in np.random.choice(fn, 10):\n",
    "for i in [51115, 152131, 155475, 90658, 114588]:\n",
    "  explain(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(\"10-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"He's dead.  Watching it live.  mms://a352.l5671334351.c56713.n.lm.akamaistream.net/D/352/56713/v0001/reflector:34351\"\"\"\n",
    "#eval(text, 1)\n",
    "#explain(text, 1)\n",
    "explain(1, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorts = [i for i in fp if len(x_train_text[i]) < 100]\n",
    "longs = [i for i in fp if len(x_train_text[i]) >= 100]\n",
    "\n",
    "shorts = np.random.choice(shorts, 5)\n",
    "longs = np.random.choice(longs, 5)\n",
    "\n",
    "print(shorts)\n",
    "for i in shorts:\n",
    "  explain(i)\n",
    "\n",
    "print(longs)\n",
    "for i in longs:\n",
    "  explain(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain(0, \"If there was a a god, I would know that you are going to hell, for being dishonest | immoral, but your days on Earth, in freedom [which you oppress] are numbered, until you go to jail or worse.\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열에서 악성 단어를 찾아내서 *로 바꿉니다.\n",
    "def filter_toxic(text):\n",
    "  pipe = make_pipeline(vectorizer, clf)\n",
    "  pred = clf.predict(vectorizer.transform([text])[0])\n",
    "\n",
    "  explainer = LimeTextExplainer(class_names=[0, 1])\n",
    "  exp = explainer.explain_instance(text, pipe.predict_proba)\n",
    "\n",
    "  result = exp.as_list()\n",
    "  toxic_list = [x[0] for x in result if x[1] >= 0.1]\n",
    "\n",
    "  filtered = text\n",
    "  for toxic in toxic_list:\n",
    "    filtered = filtered.replace(toxic, \"*\" * len(toxic))\n",
    "\n",
    "  print(\"=====================\")\n",
    "  print(\"Original Text: \\n{}\\n\\nFiltered: \\n{}\".format(text, filtered))\n",
    "  print(\"=====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_toxic(\"Please turn off your fucking cell phone please\")\n",
    "\n",
    "filter_toxic(\"\"\"\n",
    "You are wasting your time. The Fascists of Wakopedia will never allow anything bad to be awritten about a Liberal.\n",
    "Jesus you can trash all you want Wakopedia loves when people do that but don't touch a liberal or you will be banned.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "filter_toxic(\"\"\"\n",
    "uan pablo montoya\n",
    "\n",
    "Bold texthe drives fast cars and likes hot girls he is a pimp\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
