{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitsandbytes\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: filelock in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from requests->transformers) (2024.12.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting fastembed\n",
      "  Downloading fastembed-0.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from fastembed) (0.27.0)\n",
      "Collecting loguru<0.8.0,>=0.7.2 (from fastembed)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting mmh3<5.0.0,>=4.1.0 (from fastembed)\n",
      "  Downloading mmh3-4.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.26 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from fastembed) (1.26.4)\n",
      "Collecting onnx>=1.15.0 (from fastembed)\n",
      "  Downloading onnx-1.17.0-cp312-cp312-macosx_12_0_universal2.whl.metadata (16 kB)\n",
      "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from fastembed) (1.20.1)\n",
      "Collecting pillow<11.0.0,>=10.3.0 (from fastembed)\n",
      "  Using cached pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed)\n",
      "  Downloading py_rust_stemmers-0.1.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from fastembed) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from fastembed) (0.21.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from fastembed) (4.67.1)\n",
      "Requirement already satisfied: filelock in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.12.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from onnx>=1.15.0->fastembed) (5.29.2)\n",
      "Requirement already satisfied: coloredlogs in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (24.12.23)\n",
      "Requirement already satisfied: sympy in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed) (2024.12.14)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/wonik/.pyenv/versions/3.12.5/lib/python3.12/site-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n",
      "Downloading fastembed-0.5.0-py3-none-any.whl (69 kB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Downloading mmh3-4.1.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading onnx-1.17.0-cp312-cp312-macosx_12_0_universal2.whl (16.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Downloading py_rust_stemmers-0.1.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
      "Installing collected packages: py-rust-stemmers, mmh3, pillow, onnx, loguru, fastembed\n",
      "  Attempting uninstall: mmh3\n",
      "    Found existing installation: mmh3 5.0.1\n",
      "    Uninstalling mmh3-5.0.1:\n",
      "      Successfully uninstalled mmh3-5.0.1\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fastembed-0.5.0 loguru-0.7.3 mmh3-4.1.0 onnx-1.17.0 pillow-10.4.0 py-rust-stemmers-0.1.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install fastembed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. indexing: load\n",
    "DocumentLoaders를 사용하여 블로그 내용을 롣드.\n",
    "Doucment는 page_content(str)와 메타데이터(dict)를 포함하는 객체\n",
    "이 경우 urllib을 사용하여 웹 URL에서 HTML을 로드하고, BeautifulSoup을 사용하여 텍스트로 구문 분석\n",
    "bs_kwags를 통해 BeautifulSoup 파서에 매개변수를 전달하여 HTML -> 텍스트 구문 분석을 사용자 정의할 수 있다.\n",
    "\n",
    "2. indexing: split\n",
    "로드된 문서의 길이가 너무 길면 Document가 처리하기 위해서 청크단위로 분할\n",
    "문서를 재귀적으로 분할하는 RecursiveCharacterTextSplitter 이용\n",
    "\n",
    "3. indexing: store\n",
    "벡터데이터베이스에 저장\n",
    "- openai의 embedding 방식이 가장 좋음\n",
    "- 그 다음 fastembed\n",
    "\n",
    "4. Retrieval and Generation: Retrieve\n",
    "- 문서검색\n",
    "\n",
    "5. Retrieval and Generation: Generate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "import getpass \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "\n",
    "# LCEL Runnable 프로토콜 사용하여 체인을 정의하고 수행\n",
    "# 스트리밍, 비동기 및 일괄 호출을 즉시 실행\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# 양자화 설정으로 모델의 GPU 메모리 사용을 줄이도록 설정\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "hf_auth = os.environ[\"HUGGING_FACE_KEY\"]\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "# post의 타이틀, 헤더, 콘텐츠만 가져오기\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer}\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# vector store 저장\n",
    "vectorsotre = Chroma.from_documents(documents=all_splits, embedding=FastEmbedEmbeddings())\n",
    "\n",
    "print(all_splits[10].metadata)\n",
    "\n",
    "# 문서 검색\n",
    "retrieveer = vectorsotre.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "retrieved_docs = retriever.invoke(\"What are the approaches to Task Decomposition?\")\n",
    "\n",
    "print(retrieved_docs[0].page_content)\n",
    "\n",
    "# Generate\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "examples_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "print(examples_messages[0].content)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retrieveer | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
