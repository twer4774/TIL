{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradio 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \"+ name + \"!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Name Here...\"),\n",
    "    outputs=\"text\"\n",
    ")\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def gree(name, is_morning, temperature):\n",
    "    salutation = \"Good morning\" if is_morning else \"Good evening\"\n",
    "    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\n",
    "    celsius = (temperature - 32) * 5 / 9\n",
    "    return greeting, round(celsius, 2)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n",
    "    outputs=[\"text\", \"number\"],\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 이용 - 이미지 파일 색상보정\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189],\n",
    "        [0.349, 0.686, 0.168],\n",
    "        [0.282, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "demo = gr.Interface(sepia, gr.Image(), \"image\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot LLM 연결X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, No 둘 중 하나로 응답함 \n",
    "import random\n",
    "import gradio as gr\n",
    "\n",
    "def random_response(message, history):\n",
    "    return random.choice([\"Yes\", \"No\"])\n",
    "\n",
    "demo = gr.ChatInterface(random_response)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    name = gr.Textbox(label=\"Name\")\n",
    "    output = gr.Textbox(label=\"Output Box\")\n",
    "    greet_btn = gr.Button(\"Greet\")\n",
    "    greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n",
    "\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def flip_text(x):\n",
    "    return x[::-1]\n",
    "\n",
    "\n",
    "def flip_image(x):\n",
    "    return np.fliplr(x)\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"Flip text or image files using this demo.\")\n",
    "    with gr.Tab(\"Flip Text\"):\n",
    "        text_input = gr.Textbox()\n",
    "        text_output = gr.Textbox()\n",
    "        text_button = gr.Button(\"Flip\")\n",
    "    with gr.Tab(\"Flip Image\"):\n",
    "        with gr.Row():\n",
    "            image_input = gr.Image()\n",
    "            image_output = gr.Image()\n",
    "        image_button = gr.Button(\"Flip\")\n",
    "\n",
    "    with gr.Accordion(\"Open for More!\"):\n",
    "        gr.Markdown(\"Look at me...\")\n",
    "\n",
    "    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n",
    "    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio With LLM Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot UI 예시\n",
    "import gradio as gr\n",
    "import random\n",
    "import time\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "\n",
    "    def respond(message, chat_history):\n",
    "        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n",
    "        chat_history.append((message, bot_message))\n",
    "        time.sleep(2)\n",
    "        return \"\", chat_history\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.mkdir('files')\n",
    "!wget -q -O files/avatar.png https://github.com/gradio-app/gradio/raw/main/demo/chatbot_multimodal/files/avatar.png\n",
    "!wget -q https://github.com/gradio-app/gradio/raw/main/demo/chatbot_multimodal/messages_testcase.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import plotly.express as px\n",
    "\n",
    "# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n",
    "\n",
    "def print_like_dislike(x: gr.LikeData):\n",
    "    print(x.index, x.value, x.liked)\n",
    "\n",
    "def add_message(history, message):\n",
    "    for x in message[\"files\"]:\n",
    "        history.append(((x,), None))\n",
    "    if message[\"text\"] is not None:\n",
    "        history.append((message[\"text\"], None))\n",
    "    return history, gr.MultimodalTextbox(value=None, interactive=False)\n",
    "\n",
    "def bot(history):\n",
    "    history[-1][1] = \"Cool!\"\n",
    "    return history\n",
    "\n",
    "with gr.Blocks(fill_height=True) as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        elem_id=\"chatbot\",\n",
    "        bubble_full_width=False,\n",
    "        scale=1,\n",
    "    )\n",
    "\n",
    "    chat_input = gr.MultimodalTextbox(interactive=True,\n",
    "                                      file_count=\"multiple\",\n",
    "                                      placeholder=\"Enter message or upload file...\", show_label=False)\n",
    "\n",
    "    chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input])\n",
    "    bot_msg = chat_msg.then(bot, chatbot, chatbot, api_name=\"bot_response\")\n",
    "    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n",
    "\n",
    "demo.queue()\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import M\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# client = OpenAI(api_key=userdata.get(\"openAI\"))\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "print(response.choices[0].message.content)\n",
    "print(dict(response).get(\"usage\"))\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def openai_chat(prompt):\n",
    "  completions = client.chat.completions.create(\n",
    "        #engine=\"text-davinci-003\",\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        temperature=0.5,\n",
    "        )\n",
    "  #message = completions.choices[0].text\n",
    "  message = completions.choices[0].message.content\n",
    "  return message.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(input, history=[]):\n",
    "    output = openai_chat(input)\n",
    "    history.append((input, output))\n",
    "    return history, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(fn = chatbot,\n",
    "             inputs = [\"text\",'state'],\n",
    "             outputs = [\"chatbot\",'state']).launch(debug = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
