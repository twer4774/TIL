{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Token\n",
    "- LLM이 텍스트 데이터를 처리할 때 사용되는 특수한 토큰\n",
    "- 더 이상 나누어지지 않는 하나의 토큰\n",
    "    - 특별한 의미를 표현하거나, 특정 작버을 위한 신호 역할을 수행\n",
    "- LLM이 올바른 지시를 이해할 수 있도록 도와줌\n",
    "```\n",
    "    - Ex. Llama3 Instrut 같은 경우, \n",
    "    \"<|begin_of_text|>\" : Prompt의 시작을 알리는 토큰\n",
    "    \"<|start_header_id|>system<|end_header_id|>\" : 시스템 메시지를 알리는 토큰\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutli Turn Prompt Engineering\n",
    "- 여러 차례의 대화 턴(turn)을 통해 LLM에 정보를 제공하고,\n",
    "이를 바탕으로 더욱 정교한 응답을 생성하도록 하는 Prompt Engineering 기법\n",
    "- 자연스러운 대화 생성 가능 : Chatbot에서 대부분 지원되어야 함.\n",
    "- 문맥 이해 강화 : 한 번의 턴 만을 고려하는 대신, 여러 턴의 대화를 고려하면 모델이 문맥을 더 잘 이해함\n",
    "- 예시\n",
    "    ```\n",
    "    Input\n",
    "    질문 : 미국 수도가 어디야??\n",
    "    대답 : 미국의 수도는 워싱턴 D.C. 입니다.\n",
    "    질문 : 그럼 한국은?\n",
    "\n",
    "    Output\n",
    "    대답 : 한국의 수도는 서울입니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompt Engineering\n",
    "- LLM에 예제를 제공하지 않고 응답을 생성하게 하는 기법\n",
    "- LLM 성능 평가 시, 보통 ㅏㅅ용되는 기법\n",
    "\n",
    "# Few-Shot Prompt Engineering\n",
    "- LLM에 몇 가지(Few) 예제를 제공하여 응답을 생성하게 하는 기법\n",
    "- Zero-Shot 보다 더 나은 성능을 보임\n",
    "- 예제 개수에 따라 , 1-shot, 3-shot 등으로 불림\n",
    "- 일정 크기 이상의 LLM에 적용 가능\n",
    "    ```\n",
    "    ex)\n",
    "    Input\n",
    "    질문 : 너는 리뷰의 긍/부정을 알려주는 로봇이야 \"오늘 시켰는데 정말 맛있었어요\"\n",
    "    대답 : \"긍정\"\n",
    "    질문 : \"별로 였어요\"\n",
    "    대답 : \"부정\"\n",
    "    질문 : \"한번 더 시켜먹고 싶어요\"\n",
    "\n",
    "    Output\n",
    "    대답 : \"긍정\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought(CoT) Prompt Engineering\n",
    "- LLM이 답변을 생성할 때, 단순히 최종 답만 생성하는 것이 아닌, 그 과정을 단계별로 나누어서 생각하도록 하는 기법\n",
    "- 추론 과정의 투명성 : LLM의 작동방식을 더 잘 이해할 수 있음\n",
    "- 복잡한 문제 해결 능력 : 여러 단계의 추론 과정을 효과적으로 모델링할 수 있음\n",
    "- 학습 효율성 향상 : 새로운 문제에 대해 빠르게 적응할 수 있게\n",
    "```\n",
    "Input\n",
    "질문 : 너는 리뷰의 긍부정을 알려주는 로봇이야\n",
    "    왜 그렇게 생각했는지 말해주고, 그에 따른 분류를 해주면 돼.\n",
    "    \"오늘 시켰는데 정말 맛있어요\"\n",
    "대답 : \"맛있어요\" 키워드가 있으므로, \"긍정\"\n",
    "질문 : \"별로 였어요 ㅠ\"\n",
    "대답 : \"별로\" 키워드가 있으므로, \"부정\"\n",
    "질문 : \"한번 더 시켜먹고 싶어요\"\n",
    "\n",
    "Output\n",
    "대답 : \"한번 더 시켜먹고\" 키워드가 있으므로 \"긍정\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated Knowledge Prompting Engineering\n",
    "- LLM으로부터 먼저 지식을 생성하게 하도록 지시하고, 생성된 지식을 Prompt에 포함하여 답변을 생성하도록 하는 기법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Ask Prompt Enginerring\n",
    "- LLM이 스스로 질문을 던지며 문제 해결을 하면서, 최조적으로 답변을 생성하게 하는 기법"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
