{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation (합성데이터 만들기)\n",
    "- GTP를 이용해서 데이터를 만드는 케이스\n",
    "1. 구조화된 프롬프트가 있는 CSV\n",
    "2. 파이썬 프로그램으로 CSV 만들기\n",
    "3. 파이썬 프로그램으로 여러 CSV 다루기\n",
    "4. 간단한 textual 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 구조화된 CSV 파일 만들기\n",
    "- 행과 열 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "datagen_model = \"gpt-4-0125-preview\"\n",
    "\n",
    "# 집에 관한 데이터\n",
    "question = \"\"\"\n",
    "Create a CSV file with 10 rows of housing data.\n",
    "Each row should include the following fields:\n",
    " - id (incrementing integer starting at 1)\n",
    " - house size (m^2)\n",
    " - house price\n",
    " - location\n",
    " - number of bedrooms\n",
    "\n",
    "Make sure that the numbers make sense (i.e. more rooms is usually bigger size, more expensive locations increase price. more size is usually higher price etc. make sure all the numbers make sense). Also only respond with the CSV.\n",
    "\"\"\"\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=datagen_model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to generate synthetic data\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    ")\n",
    "\n",
    "res = response.choices[0].message.content\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 파이썬으로 CSV 만들기\n",
    "- 1번 방식은 토큰 수 제한으로 많은 데이터를 만들기 어려움\n",
    "- LLM에게 데이터를 생성할 수 있는 프로그램을 만들어달라고 요청함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Create a Python program to generate 100 rows of housing data.\n",
    "I want you to at the end of it output a pandas dataframe with 100 rows of data.\n",
    "Each row should include the following fields:\n",
    " - id (incrementing integer starting at 1)\n",
    " - house size (m^2)\n",
    " - house price\n",
    " - location\n",
    " - number of bedrooms\n",
    "\n",
    "Make sure that the numbers make sense (i.e. more rooms is usually bigger size, more expensive locations increase price. more size is usually higher price etc. make sure all the numbers make sense).\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=datagen_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to generate synthetic data.\"},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "  ]\n",
    ")\n",
    "res = response.choices[0].message.content\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multitable CSV를 가진 파이썬 프로그램\n",
    "- 연관되어 있는 테이블을 연결한 데이터 (연관관계)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Create a Python program to generate 3 different pandas dataframes.\n",
    "\n",
    "1. Housing data\n",
    "I want 100 rows. Each row should include the following fields:\n",
    " - id (incrementing integer starting at 1)\n",
    " - house size (m^2)\n",
    " - house price\n",
    " - location\n",
    " - number of bedrooms\n",
    " - house type\n",
    " + any relevant foreign keys\n",
    "\n",
    "2. Location\n",
    "Each row should include the following fields:\n",
    " - id (incrementing integer starting at 1)\n",
    " - country\n",
    " - city\n",
    " - population\n",
    " - area (m^2)\n",
    " + any relevant foreign keys\n",
    "\n",
    " 3. House types\n",
    " - id (incrementing integer starting at 1)\n",
    " - house type\n",
    " - average house type price\n",
    " - number of houses\n",
    " + any relevant foreign keys\n",
    "\n",
    "Make sure that the numbers make sense (i.e. more rooms is usually bigger size, more expensive locations increase price. more size is usually higher price etc. make sure all the numbers make sense).\n",
    "Make sure that the dataframe generally follow common sense checks, e.g. the size of the dataframes make sense in comparison with one another.\n",
    "Make sure the foreign keys match up and you can use previously generated dataframes when creating each consecutive dataframes.\n",
    "You can use the previously generated dataframe to generate the next dataframe.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=datagen_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to generate synthetic data.\"},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "  ]\n",
    ")\n",
    "res = response.choices[0].message.content\n",
    "print(res)\n",
    "\n",
    "\"\"\"\n",
    "To accomplish this task, first, we will need to install pandas by running:\n",
    "\n",
    "```\n",
    "!pip install pandas\n",
    "```\n",
    "\n",
    "Below is a Python program to generate the 3 different pandas DataFrames according to your requirements:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to generate house prices based on several factors\n",
    "def generate_house_price(size, bedrooms, location_id, house_type_id):\n",
    "    base_price = 100000  # Base price for calculation\n",
    "    price = base_price + (size * 3000) + (bedrooms * 50000)\n",
    "    price_modifier = 1.0 + (location_id * 0.05) + (house_type_id * 0.1)\n",
    "    return round(price * price_modifier)\n",
    "\n",
    "# 1. Generating 'Location' DataFrame\n",
    "location_data = {\n",
    "    \"id\": range(1, 6),  # Assuming 5 unique locations for simplicity\n",
    "    \"country\": [\"CountryA\", \"CountryB\", \"CountryC\", \"CountryD\", \"CountryE\"],\n",
    "    \"city\": [\"City1\", \"City2\", \"City3\", \"City4\", \"City5\"],\n",
    "    \"population\": [500000, 200000, 1000000, 750000, 300000],\n",
    "    \"area_m2\": [100000, 50000, 200000, 150000, 120000]\n",
    "}\n",
    "location_df = pd.DataFrame(location_data)\n",
    "\n",
    "# 2. Generating 'House types' DataFrame\n",
    "house_types_data = {\n",
    "    \"id\": range(1, 4),  # 3 Types of houses\n",
    "    \"house_type\": [\"Apartment\", \"Detached\", \"Townhouse\"],\n",
    "    \"average_house_type_price\": [200000, 300000, 250000],  # Base prices for simplicity\n",
    "    \"number_of_houses\": [120, 70, 45]\n",
    "}\n",
    "house_types_df = pd.DataFrame(house_types_data)\n",
    "\n",
    "# 3. Generating 'Housing' DataFrame\n",
    "np.random.seed(42)  # For consistent random data\n",
    "\n",
    "housing_data = {\n",
    "    \"id\": range(1, 101),  # 100 Houses\n",
    "    \"house_size_m2\": np.random.randint(50, 500, 100),  # Random sizes between 50 and 500 m^2\n",
    "    \"location_id\": np.random.randint(1, 6, 100),  # Assuming 5 locations from 'Location' DataFrame\n",
    "    \"number_of_bedrooms\": np.random.randint(1, 6, 100),  # Between 1 and 5 bedrooms\n",
    "    \"house_type_id\": np.random.randint(1, 4, 100)  # 3 Types from 'House types' DataFrame\n",
    "}\n",
    "\n",
    "# Placeholder for house prices, will be generated next\n",
    "housing_data[\"house_price\"] = [0] * 100\n",
    "\n",
    "# Generating 'House price' based on size, bedroom count, location, and house type\n",
    "for i in range(100):\n",
    "    size = housing_data[\"house_size_m2\"][i]\n",
    "    bedrooms = housing_data[\"number_of_bedrooms\"][i]\n",
    "    location_id = housing_data[\"location_id\"][i]\n",
    "    house_type_id = housing_data[\"house_type_id\"][i]\n",
    "    housing_data[\"house_price\"][i] = generate_house_price(size, bedrooms, location_id, house_type_id)\n",
    "\n",
    "housing_df = pd.DataFrame(housing_data)\n",
    "\n",
    "# Display the DataFrames for inspection\n",
    "print(\"Location DataFrame:\")\n",
    "print(location_df, \"\\n\")\n",
    "\n",
    "print(\"House Types DataFrame:\")\n",
    "print(house_types_df, \"\\n\")\n",
    "\n",
    "print(\"Housing DataFrame:\")\n",
    "print(housing_df.head())  # Displaying only the first 5 rows for brevity\n",
    "\n",
    "```\n",
    "\n",
    "This script first generates a DataFrame for locations and house types, which are simpler and not dependent on any other data. These are then used to create a more complex Housing DataFrame where house prices are determined by a custom function `generate_house_price`, taking into account several factors like house size, number of bedrooms, location, and house type. \n",
    "\n",
    "Please replace `\"CountryA\"`, `\"CountryB\"`, etc., and `\"City1\"`, `\"City2\"`, etc., with actual names as needed. The `generate_house_price` function and the random data are simplified for this example and can be adjusted to reflect more complex and realistic scenarios.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 간단한 텍스트 데이터\n",
    "- Input과 Output을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string = \"\"\n",
    "for i in range(3):\n",
    "  question = f\"\"\"\n",
    "  I am creating input output training pairs to fine tune my gpt model. The usecase is a retailer generating a description for a product from a product catalogue. I want the input to be product name and category (to which the product belongs to) and output to be description.\n",
    "  The format should be of the form:\n",
    "  1.\n",
    "  Input: product_name, category\n",
    "  Output: description\n",
    "  2.\n",
    "  Input: product_name, category\n",
    "  Output: description\n",
    "\n",
    "  Do not add any extra characters around that formatting as it will make the output parsing break.\n",
    "  Create as many training pairs as possible.\n",
    "  \"\"\"\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    model=datagen_model,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to generate synthetic data.\"},\n",
    "      {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "  )\n",
    "  res = response.choices[0].message.content\n",
    "  output_string += res + \"\\n\" + \"\\n\"\n",
    "print(output_string[:1000]) #displaying truncated response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex to parse data\n",
    "pattern = re.compile(r'Input:\\s*(.+?),\\s*(.+?)\\nOutput:\\s*(.+?)(?=\\n\\n|\\Z)', re.DOTALL)\n",
    "matches = pattern.findall(output_string)\n",
    "products = []\n",
    "categories = []\n",
    "descriptions = []\n",
    "\n",
    "for match in matches:\n",
    "    product, category, description = match\n",
    "    products.append(product.strip())\n",
    "    categories.append(category.strip())\n",
    "    descriptions.append(description.strip())\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 불균형하고 다양하지 않은 데이터 다루기\n",
    "- 데이터 일관성과 동일성, 다양성을 높이기 위한 방법\n",
    "- 클러스터링 => k-means 알고리즘 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입 출력 쌍 만들기\n",
    "\n",
    "output_string = \"\"\n",
    "for i in range(3):\n",
    "  question = f\"\"\"\n",
    "  I am creating input output training pairs to fine tune my gpt model. I want the input to be product name and category and output to be description. the category should be things like: mobile phones, shoes, headphones, laptop, electronic toothbrush, etc. and also more importantly the categories should come under 4 main topics: vehicle, clothing, toiletries, food)\n",
    "  After the number of each example also state the topic area. The format should be of the form:\n",
    "  1. topic_area\n",
    "  Input: product_name, category\n",
    "  Output: description\n",
    "\n",
    "  Do not add any extra characters around that formatting as it will make the output parsing break.\n",
    "\n",
    "  Here are some helpful examples so you get the style of output correct.\n",
    "\n",
    "  1) clothing\n",
    "  Input: \"Shoe Name, Shoes\"\n",
    "  Output: \"Experience unparalleled comfort. These shoes feature a blend of modern style and the traditional superior cushioning, perfect for those always on the move.\"\n",
    "  \"\"\"\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to generate synthetic data.\"},\n",
    "      {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "  )\n",
    "  res = response.choices[0].message.content\n",
    "  output_string += res + \"\\n\" + \"\\n\"\n",
    "print(output_string[:1000]) #displaying truncated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화로 데이터가 잘린것들 정제\n",
    "pattern = re.compile(r'(\\d+)\\) (\\w+(?: \\w+)?)\\s*Input: \"(.+?), (.+?)\"\\s*Output: \"(.+?)\"', re.DOTALL)\n",
    "matches = pattern.findall(output_string)\n",
    "\n",
    "\n",
    "topics = []\n",
    "products = []\n",
    "categories = []\n",
    "descriptions = []\n",
    "\n",
    "for match in matches:\n",
    "    number, topic, product, category, description = match\n",
    "    topics.append(topic)\n",
    "    products.append(product)\n",
    "    categories.append(category)\n",
    "    descriptions.append(description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Product': products,\n",
    "    'Category': categories,\n",
    "    'Description': descriptions\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "\n",
    "    return response.data[0].embedding\n",
    "\n",
    "embedding_model = \"text-embedding-3-small\"\n",
    "df[\"embedding\"] = df.Category.apply(lambda x: get_embedding(x, model=embedding_model))\n",
    "\n",
    "matrix = np.vstack(df.embedding.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means 알고리즘으로 군집화 예시\n",
    "\n",
    "# Determine the optimal number of clusters using the elbow method\n",
    "# inertias = []\n",
    "# range_of_clusters = range(1, 13)  # Adjust the range as necessary\n",
    "\n",
    "# for n_clusters in range_of_clusters:\n",
    "#     kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=42, n_init=10)\n",
    "#     kmeans.fit(matrix)\n",
    "#     inertias.append(kmeans.inertia_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the elbow plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(range_of_clusters, inertias, '-o')\n",
    "# plt.title('Elbow Method to Determine Optimal Number of Clusters')\n",
    "# plt.xlabel('Number of Clusters')\n",
    "# plt.ylabel('Inertia')\n",
    "# plt.xticks(range_of_clusters)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=42)\n",
    "kmeans.fit(matrix)\n",
    "labels = kmeans.labels_\n",
    "df[\"Cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = df[\"Cluster\"].value_counts().sort_index()\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽 별로 데이터 가져오기\n",
    "\n",
    "#selected_examples = df.groupby('Cluster').apply(lambda x: x.sample(3)).reset_index(drop=True)\n",
    "selected_examples = df.groupby('Cluster').apply(lambda x: x.sample(min(len(x), 3))).reset_index(drop=True)\n",
    "\n",
    "# Format the selected examples\n",
    "formatted_examples = \"\\n\".join(\n",
    "    f'Input: \"{row[\"Product\"]}, {row[\"Category\"]}\"\\nOutput: \"{row[\"Description\"]}\"\\nCluster: \"{row[\"Cluster\"]}\"'\n",
    "    for _, row in selected_examples.iterrows()\n",
    ")\n",
    "\n",
    "topic_prompt = f\"\"\"\n",
    "    I previously generated some examples of input output trainings pairs and then I clustered them based on category. From each cluster I picked 3 example data point which you can find below.\n",
    "    I want you identify the broad topic areas these clusters belong to.\n",
    "    Previous examples:\n",
    "    {formatted_examples}\n",
    "\n",
    "\n",
    "    Your output should be strictly of the format:\n",
    "    Cluster: number, topic: topic\n",
    "    Cluster: number, topic: topic\n",
    "    Cluster: number, topic: topic\n",
    "\n",
    "    Do not add any extra characters around that formatting as it will make the output parsing break.\n",
    "    \"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=datagen_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed analyze clustered data\"},\n",
    "    {\"role\": \"user\", \"content\": topic_prompt}\n",
    "  ]\n",
    ")\n",
    "res = response.choices[0].message.content\n",
    "\n",
    "pattern = r\"Cluster: (\\d+), topic: ([^\\n]+)\"\n",
    "matches = re.findall(pattern, res)\n",
    "clusters = [{\"cluster\": int(cluster), \"topic\": topic} for cluster, topic in matches]\n",
    "json_output = json.dumps(clusters, indent=2)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다양성을 늘리는 방법\n",
    "\n",
    "#selected_examples = df.groupby('Cluster').apply(lambda x: x.sample(3)).reset_index(drop=True)\n",
    "selected_examples = df.groupby('Cluster').apply(lambda x: x.sample(min(len(x), 3))).reset_index(drop=True)\n",
    "\n",
    "# Format the selected examples\n",
    "formatted_examples = \"\\n\".join(\n",
    "    f'Input: \"{row[\"Product\"]}, {row[\"Category\"]}\"\\nOutput: \"{row[\"Description\"]}\"\\nCluster: \"{row[\"Cluster\"]}\"'\n",
    "    for _, row in selected_examples.iterrows()\n",
    ")\n",
    "\n",
    "topic_prompt = f\"\"\"\n",
    "    I previously generated some examples of input output trainings pairs and then I clustered them based on category. From each cluster I picked 3 example data point which you can find below.\n",
    "    I want to promote diversity in my examples across categories so follow the procedure below:\n",
    "    1. You must identify the broad topic areas these clusters belong to.\n",
    "    2. You should generate further topic areas which don't exist so I can generate data within these topics to improve diversity.\n",
    "\n",
    "\n",
    "    Previous examples:\n",
    "    {formatted_examples}\n",
    "\n",
    "\n",
    "    Your output should be strictly of the format:\n",
    "\n",
    "    1. Cluster topic mapping\n",
    "    Cluster: number, topic: topic\n",
    "    Cluster: number, topic: topic\n",
    "    Cluster: number, topic: topic\n",
    "\n",
    "    2. New topics\n",
    "    1. topic\n",
    "    2. topic\n",
    "    3. topic\n",
    "    4. topic\n",
    "\n",
    "    Do not add any extra characters around that formatting as it will make the output parsing break. It is very important you stick to that output format\n",
    "    \"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=datagen_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to analyze clustered data\"},\n",
    "    {\"role\": \"user\", \"content\": topic_prompt}\n",
    "  ]\n",
    ")\n",
    "res = response.choices[0].message.content\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = res.split(\"\\n\\n\")\n",
    "cluster_mapping_part = parts[0]\n",
    "new_topics_part = parts[1]\n",
    "\n",
    "# Parse cluster topic mapping\n",
    "cluster_topic_mapping_lines = cluster_mapping_part.split(\"\\n\")[1:]  # Skip the first two lines\n",
    "cluster_topic_mapping = [{\"cluster\": int(line.split(\",\")[0].split(\":\")[1].strip()), \"topic\": line.split(\":\")[2].strip()} for line in cluster_topic_mapping_lines]\n",
    "\n",
    "# Parse new topics\n",
    "new_topics_lines = new_topics_part.split(\"\\n\")[1:]  # Skip the first line\n",
    "new_topics = [line.split(\". \")[1] for line in new_topics_lines]\n",
    "\n",
    "cluster_topic_mapping, new_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
