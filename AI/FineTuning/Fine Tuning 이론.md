- Transformer란?
	- LLM이 사용하는 모델(번역기)
	- Sequence to Sequence Learning이 목표
	- RNN + Attention에 기반한 인코더 + 디코더 구조
	- GPT : Transformer에서 디코더 특성을 최대한 활용한 모델
	- BERT : Transformer에서 인코더 특성을 최대한 활용한 모델
- 파라미터 vs 하이퍼 파라미터
	- 파라미터
		- 모델이 데**이터로부터 학습하는 값들**
		- 학습 데이터를 통해 업데이트 되고, 모델의 예측을 결정하는 핵심 요소
		- 학습하는 동안 자동으로 조정이되고 조정함으로써 예측 오차 최소화
		- 선형 회귀모델에서 가중치(weight), 절편(bias) 등
	- 하이퍼 파라미터
		- 모델의 **학습 방식을 결정하는 값들**
		- 사용자에 의해 미리 설정
		- 학습과정에서 자동으로 변겨오디지 않음
		- 정해진 최적의 값이 없고, 모델에서 외적인 요소, 데이터 분서을 통해 얻어지지 않음
		- 결정 트리의 최대 깊이, kNN의 이웃 수, 신경망의 학습률과 에포크 수
		- 하이퍼 파라미터 기초
			- 학습율 (learning rate) : Gradient의 방향으로 얼마나 빠르게 이동할 것인지 결정하는 변수. 너무 낮으면 속도가 느리다.
			- 모멘텀 (momentum) : 학습 방향을 유지하려는 성질. 같은 방향의 학습이 진행되면 학습 속도가 빠르다.
			- 에포크 (epoch) : 전체 트레이닝 셋이 신경망을 통과한 횟수
			- 배치 사이즈 : 최소사이즈 32, GPU의 물리적인 구조로 인해 항상 2의 제공으로 설정
			- 반복 : 1-epoch를 마치는데 필요한 파라미터 업데이터 횟수
			- 손실함수 (Cost Function) : 입력에 따른 기대 값과 실제 값의 차이를 계산하는 함수
			- 정규화 파라미터 (Regularization parameter) : L1 또는 L2 정규화 방법 사용
	- OpenAI Playground 하이퍼파라미터
		- Temperature : 답변의 창의성
		- To P : 모델의 랜덤성. 값이 낮을 수록 정확하고 사실적인 답변 
		- Maximum Tokens : 토큰 수 관리 (최대 4000개 정도)
		- Stop sequences : 모델의 토큰 생성을 중지하는 문자열
		- Frequence penalty : 토큰이 나타나는 빈도에 비례하여 패널티를 생성
		- Presence penalty : 토큰이 발생했는지 여부를 기준으로 비례 대신 일률적인 패널티 부여
	- PEFT (Parameter Efficient Fine-Tuning)
		- 적은 매개변수 학습으로 빠른 시간에 새로운 문제를 해결하는 Fine-Tuning
		- 다양한 언어와 도메인의 데이터 모델을 적용할 때 유용
		- 각 도메인 또는 언어별로 작은 체크포인트만 로컬에 저장하면 효율적으로 작동
		- 다양한 태스크에 모델을 신속히 적용할 때 유용
		- LoRA (Low Rank Adaptation)
			- 사전 훈련된 LLM을 적은 컴퓨팅 메모리로 학습하기 위해 나온방법
			- 업데이터 행렬로 알려진 순위 분해 가중치 행렬 쌍을 기존 가중치에 도입 
- Fine Tuning
	- 기계, 시스템 등의 미세 조정을 의미
	- 모델의 특정 레이블에 저장된 예제를 제공한 다음 '역전파'라는 프로세스를 통해 가중치를 업데이트 하는 행위
	- 특정 작업이나 도메인에 높은 적합성을 확복하기 위해 미리 훈련된 모델에 특정 데이터 셋을 사용하여 추가 학습을 수행하는 것을 뜻함
	- Fine Tuning 단계
		- ![[Pasted image 20241227103951.png]]
		- Pretraining Model : GPT 같이 이미 학습되어 있는 모델 
		- Model (Transfer Model)  : 전이 학습. Pretraining Model로 학습된 데이터
		- Finetuning Model : 전이 학습 된 모델에서 특정 도메인만 가중치를 업데이트한 모델
	- Fine Tuning 절차
		- 데이터셋 준비
		- 사전 학습 및 파운데이션 모델 선택
		- 파인튜닝 전략 정의
		- 하이퍼 파라미터 설정
		- 모델 매개변수 초기화
		- 파인튜닝 학습
		- 모델 평가 및 튜닝
		- 성능 테스트 및 배포
## Fine Tuning 방법
- Full Fine-tuning
	- 모든 모델 변수를 포함하여 사전 학습된 모델 전체를 ine-tuning하는 작업을 의미
	- 사전 학습된 모델의 모든 레이어와 매개 변수가 업데이트되고 최적화되어 대상 작업의 요구 사항에 맞게 조정
	- 일반적으로 자겁과 사전 학습된 모델 사이에 큰 차이가 있거나 작업에서 모델의 유연성과 적응성이 높아야 하는 경우에 적합
	- Full Fine-tuning에는 상당한 리소스와 시간이 필요하지만 그만큼 더 나은 성능을 얻을 수 있음
- Feature extraction(Repurposing)
	- 사전 학습된 모델의 하위 레이어를 그대로 유지하면서 모델의 상위 레이어 또는 선택된 몇개의 레이어를 Fine-tuning을 의미
	- 사전 학습된 모델에 대한 일반적인 지식을 유지하며서 최상위 레이어를 특정 작업에 적용
	- 대상 작업과 사전 학습된 모델 사이에 특정 유사성이 있거나 작업 데이터셋이 작은 경우에 적합
	- 몇개의 레이어만 업데이트되므로 Full fine-tuning에 비해 필요한 리소스와 시간이 적지만 경우에 따라 약간의 성능 저하가 발생
## Fine-tuning 유형
- Supervised Fine-tuning : 미세 조정 단계에서 레이블이 지정된 학습 데이터셋을 사용하는 프로세스
	- 질문과 답을 함께 주는 방법
	- 도메인 특화에 적합함
- Unsupervised Fine-tuning : 레이블이 지정되지 않는 학습 데이터셋을 사용하는 것을 포함