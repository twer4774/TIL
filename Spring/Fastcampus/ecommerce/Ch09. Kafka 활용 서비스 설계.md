# 1. Use Case에 기반한 서비스 요구사항 정의 for Kafka
## 요구사항 정의
- 서비스명 : 프로모션 노출 졸직 실시간 변경 서비스 - 실시간 프로모션 구매 포션 확인 서비스
- 서비스 요구사항 정의
	1. 요구사항 : 프로모션 구매 실적 수집 및 Processing
	2. 요구사항 설명 : 모든 구매내역 중 프로모션을 통해 구매된 제품의 구매로그를 실시간으로 수집하여 재발행
	3. 중요도 : 상, 난이도 : 중
	- 고려 사항
		- 구매이력 중 판매된 상품의 프로모션 해당 여부는 어떻게 알 수 있는가?
		 => promotion click 여부를 user behavior topic 에서 확인할 수 있음
		- 구매 Transaction이 발생된 후 몇 초 이내에 데이터가 재발행되어야 하는가?
		 => 2초
		- 재발행 해야하는 데이터 포맷? Topic 정보
		 => json, PromotionLogic topic
		- 구매내역 attribute중 포함되어야 하는 정보는? (구매자, 구매시각, 결제방법 등)
		- 실시간 구매로그가 추후 다른 곳에 쓰일 수 있는가?
		 => 연령별 프로모션 반응도 분석에 쓰일 수 있음
		- 저장공간의 문제 발생 시 서비스에서 보장해야 하는 데이터 보관 기간
		 => 5일
		- 이력을 넘겨주는 방식
		 => API, LogFile, Kafka
		- 노출되지 않아야 할 개인정보
		 => ID, 카드정보
	- 고려 사항 정리
		- Kafka로 데이터를 넘겨받아서 다른 정보들에 대한 추가, 수정 후 Topic으로 넘기기

# 2. Use Case에 기반한 서비스 품질요건 정의 for Kafka
## 프로모션 구매실적 수집 서비스의 품질 요건
1. 가용성 (Availability) : 99.95% (년 4.38 시간)
	- 노드 1개는 Down될 수 있기에 3개로 구성, RTO (5분), RPO (60초)
		- RTO (Recovery Time Objective) : 목표 복구 시간
			- 장애 발생 시 시스템을 원 상태로 복원하는데 소요되는 시간
			- 서비스가 재개될 때까지 걸리는 시간
		- RPO (Recovery Point Objective) : 목표 복구 시점
			- 장애 발생 시 비즈니스 연속을 위해 어느 시점으로 백업할 지 결정하게 될 지표
			- 현재로부터 가장 가까운 백업지점까지의 목표 시간
	- 노드 1개가 Down되더라도 Pub/Sub에 지장이 없도록 Topic Replication
2. 성능, 용량
	- 200 Ops/sec, 초당 100개 구매이력 발생, 100개의 광고 클릭이력 발생
	- Sample Data : 200 Byte가 60초 평균 200개 발생
	- Replica: 1, Retention: 5 days
	- 200(Byte) * 2(repl) * 1440(분) * 5(일) * 200(개) = 34.5Gb + buffer 5Gb
3. 비용 : 얼마만큼의 자원을 사용하여 해당 기능을 구축할 것인가?
	- H/W : 4 Core, Gb, 1Gb disk VM * 3(Kafka) + 2 core, 4GB VM * 3(Zookeeper+cmak), 2 core, 1GB VM(Msg Service)
	- S/W : 오픈소스, 인력 : 자체 개발
4. 보안 : 내부망 안에서 사용되기에 관계 없다.
5. 효율성 : API를 통해 Data 입력 가능, log 통해 입력 가능하도록 Guide 제공


# 3. 서비스 논리 설계 for Kafka
## 설계 요건과 자원 살펴보기
- Msg Service (2 Core, 2 Gb)
- Kafka Cluster (4 Core, 8 Gb)
- Zookeeper ensemble (2 Core, 4 Gb)
- HDD/SSD (40 Gb)
### 협의 완료 내용
- 실시간 Promotion Reaction Data (User Behavior) Topic : promo_behavior
- 실시간 구매 이력 Data Topic : purchase
- 구매 시점에 광고에 관련된 행위 (click, view)  여뷰를 파악하여 영향이 있었는지 정보를 추가
- 관련행위 후 5분 이내의 작업이 구매에 영향을 주었을 것이라 판단하여 정보를 기재
- 관련 여부는 promotion_affect라는 정보로 0(false), 1(true)과 같이 추가
- 정보 추가 후 promotion_affect=1인 경우 promotion topic에 나누어 재발행

## Topology, Kafka Stream
- Kafka에서 Topology : 프로세스와 토픽등이 연결된 모습, 메시지의 흐름 + 기본적 처리 내용
- Kafka Stream이란 : Library, 프로세스 내부적으로 pipeline을 구성하기 위해 사용
	- 민감정보(고객개인정보, 결제관련 정보) masking
	- 데이터 표준화 (Name, Time, Currency(10,000 / 10000), Field명)
	- 병합
	- 필터링